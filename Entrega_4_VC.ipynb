{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a27ae10d",
   "metadata": {},
   "source": [
    "# Desarrollar un prototipo que procese varios vídeos propios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a3651",
   "metadata": {},
   "source": [
    "## Detectar y seguir a las personas y vehículos presentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67964b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total objetos detectados:\n",
      "car: 1441\n",
      "person: 239\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIGURACIÓN\n",
    "# ---------------------------\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "model = YOLO('yolo11n.pt')  # YOLOv11 nano\n",
    "classes_to_detect = [0, 2]  # 0=person, 2=car\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "video_path = \"vc_coches.mp4\"\n",
    "output_video_path = \"salida_yolo_tracking_sinOCR.mp4\"\n",
    "output_csv_path = \"detecciones_yolo_tracking_sinOCR.csv\"\n",
    "\n",
    "# Contador de objetos por clase\n",
    "total_count = defaultdict(int)\n",
    "\n",
    "# ---------------------------\n",
    "# ABRIR VIDEO Y GUARDAR SALIDA\n",
    "# ---------------------------\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# ---------------------------\n",
    "# CSV\n",
    "# ---------------------------\n",
    "csv_file = open(output_csv_path, mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\n",
    "    \"fotograma\", \"tipo_objeto\", \"confianza\", \"id_tracking\",\n",
    "    \"x1\",\"y1\",\"x2\",\"y2\",\n",
    "    \"matricula\", \"conf_matricula\", \"mx1\",\"my1\",\"mx2\",\"my2\",\"texto_matricula\"\n",
    "])\n",
    "\n",
    "frame_id = 0\n",
    "\n",
    "# ---------------------------\n",
    "# PROCESAR VIDEO\n",
    "# ---------------------------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_id += 1\n",
    "\n",
    "    # Detecta y trackea personas y coches\n",
    "    results = model.track(\n",
    "        source=frame,\n",
    "        persist=True,\n",
    "        classes=classes_to_detect,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "\n",
    "    if results and results[0] is not None:\n",
    "        r = results[0]\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            track_id = int(box.id[0]) if box.id is not None else -1\n",
    "            label = classNames[cls] if cls < len(classNames) else f\"class_{cls}\"\n",
    "\n",
    "            # Incrementa contador\n",
    "            total_count[label] += 1\n",
    "\n",
    "            # Dibuja bounding box e ID\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(annotated_frame, f\"{label} ID:{track_id} {conf:.2f}\", \n",
    "                        (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "\n",
    "            # Escribir en CSV (sin matrícula)\n",
    "            csv_writer.writerow([\n",
    "                frame_id, label, f\"{conf:.2f}\", track_id,\n",
    "                x1, y1, x2, y2,\n",
    "                \"\", \"\", 0,0,0,0,\"\"\n",
    "            ])\n",
    "\n",
    "    out.write(annotated_frame)\n",
    "    cv2.imshow(\"YOLO Tracking Personas y Coches\", annotated_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# ---------------------------\n",
    "# FIN\n",
    "# ---------------------------\n",
    "cap.release()\n",
    "out.release()\n",
    "csv_file.close()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Muestra totales\n",
    "print(\"Total objetos detectados:\")\n",
    "for k,v in total_count.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc8640",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo YOLOv8 personalizado para la detección de matrículas.\n",
    "Se utilizó un conjunto de datos de matrículas disponible en [Kaggle](https://www.kaggle.com/) con anotaciones en formato YOLO, descrito en el archivo `data.yaml`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be03b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'staticmethod' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_directml\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wafat\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch_directml\\__init__.py:27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# # Register backend to support AMP\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPrivateUse1Module\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_available\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a bool indicating if DML is currently available.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wafat\\anaconda3\\envs\\VC_P4\\lib\\site-packages\\torch_directml\\__init__.py:74\u001b[0m, in \u001b[0;36mPrivateUse1Module\u001b[1;34m()\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdisable_tiled_resources\u001b[39m(is_disabled):\n\u001b[0;32m     71\u001b[0m     torch_directml_native\u001b[38;5;241m.\u001b[39mdisable_tiled_resources(is_disabled)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_float64_support\u001b[39m(device_id \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_directml_native\u001b[38;5;241m.\u001b[39mhas_float64_support(device_id)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgpu_memory\u001b[39m(device_id \u001b[38;5;241m=\u001b[39m default_device(), mb_per_tile \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[1;31mTypeError\u001b[0m: 'staticmethod' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch_directml\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "device = torch_directml.device() \n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # Modelo base\n",
    "model.train(data=\"ruta/a/dataset.yaml\", epochs=50, imgsz=640, device=device)\n",
    "\n",
    "model.train(\n",
    "    data=\"data.yaml\",  \n",
    "    imgsz=416,\n",
    "    epochs=10,\n",
    "    batch=4,\n",
    "    device=device,\n",
    "    name=\"matriculas_detector2\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
